import sys
print('python:{}'.format(sys.version))
import scipy
print('scipy:{}'.format(scipy.__version__))
import numpy
print('Numpy: {}'.format(numpy.__version___))
import matplotlib 
print('Matplotlib:{}'.format(matplotlib.__version__))
import pandas
print('PandasP:{}'.format(pandas.__version__))
import sklearn
print('sklearn :{}'.format(sklearn.___version__))
import pandas 
from pandas.plotting import scatter_matrix
from matplotlib import pyplot
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import stratifiedKFold
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.navie_bayas import GaussianNB
from sklearn.svm import SVC
from sklearn import model_selection
from sklearn.ensemble import VotingClassifier
# loading the data
url="https://raw.githubusercontent.com/jbrownlee/datasets/master/iris.csv"
names = ['sepal-length','sepal-width','petal-length','petal-width','class']
dataset=read_csv(url,names=names)
# dimensions of the dataset
print(dataset.shape)
#take a peek at the data
print(datatset.head(20))
#statictical summary 
print(dataset.describe())
# class distributon 
print(dataset.groupby('class').size())
# univariate plots-box and whisker plots
dataset.plot(kind='box',subplots=true,layout=(2,2), sharex=False, sharey=False)
pyplot.show()
#histogram of the variable
dataset.hist()
pyplot.show()
# multivariate plots
scatter_matrix(dataset)
pyplot.show()
# ctreating a validation dataset
# splitting dataset
array = dataset.values
x= array[:,0:4]
y=array[:,4]
x_traion, x_validation, y_train, y_validation= train_test_split(x,y,test_size=0.2,random_state=1)
# logistic  Regression 
# Linear discriminant Analysis
# K-Nearest neighbors
# classification and regression trees
# Gaussian Naive Bayes
# support vector Machines
# building models
mode4ls =[]
models.append(('LR',LogisticRegression(solbver='liblinear',multi_class='over')))
models.append(('LDA',LinearDiscriminantAnalysis()))
models.append(('KNN',KNeighborsClassifier()))
models.append(('NB',GaussianNB()))
models.append(('SVM',SVC(gamma='auto')))
# evaluate the created models
results = []
names = []
for name, model in models:
      Kfold = stratifiedKFold(n_splits=10,random_state=1)
      cv_results= cross_val_score(model,x_train,y_train, cv=Kfold, scoring ='accuracy')
      results.append(cv_results)
      names.append(name)
      print('%s: %f(%f)'% (name,cv_results.mean(), cv_results.std()))
# compare our models
pyplot.boxplot(results, labels=names)
pyplot.tktle('Algorithm comparison')
pyplot.show()
# make prediction on svm
model = svc(gamma = 'auto')
model.fit(x_train, y_train)
predictions = model.predict(x_validation)
# evaluate our predictions 
print(accuracy_score(y_validation, predictions))
print(confusion_matrix(y_validation,prediction))
print(classification_report(y_validation,prdiction))
